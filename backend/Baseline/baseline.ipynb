{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier  # Import Decision Tree Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split  # Import train_test_split function\n",
    "from sklearn import metrics  # Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    \"xg\": XGBClassifier(),\n",
    "    \"tree\": DecisionTreeClassifier(max_depth=3, min_samples_split=2, min_samples_leaf=1, max_features=None),\n",
    "    \"random_forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"gb\": GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "\n",
    "def load_data(file_path: Path | str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the data from the specified file path.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    return data\n",
    "\n",
    "def merge_selected_columns_from_dfs(df1: pd.DataFrame, df2: pd.DataFrame, columns_to_merge: List[str]) -> pd.DataFrame:\n",
    "    # Ensure the columns to merge also include the key columns with their names as they appear in df2\n",
    "    key_columns_df2 = ['cyclist_id', 'date']\n",
    "    all_columns_to_merge = list(set(columns_to_merge + key_columns_df2))\n",
    "\n",
    "    # Select only the necessary columns from df2\n",
    "    df2_selected = df2[all_columns_to_merge]\n",
    "\n",
    "    # Merge the DataFrames on the key columns using an inner join\n",
    "    merged_df = pd.merge(df1, df2_selected, on=['cyclist_id', 'date'], how='inner')\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "def prepare_data(df: pd.DataFrame, window_size_past: int, window_size_future: int):\n",
    "    prepared_data = {}\n",
    "    feature_cols = df.columns\n",
    "    remove_keys = [\"day\", \"year\", \"month\", \"workout_week\", \"workout_title\", \"workout_type\", \"_id\"]\n",
    "    feature_cols = list(filter(lambda col: not any([key in col for key in remove_keys]), feature_cols))\n",
    "    # Iterate over the unique cyclist_ids to handle each cyclist's data separately\n",
    "    for cyclist_id in df['cyclist_id'].unique():\n",
    "        cyclist_data = df[df['cyclist_id'] == cyclist_id]\n",
    "        prepared_data[cyclist_id] = pd.DataFrame()\n",
    "\n",
    "        # Create rolling windows of features\n",
    "        for i in range(1, window_size_past + 1):\n",
    "            for feature in feature_cols:\n",
    "                prepared_data[cyclist_id][f'{feature}{i}'] = cyclist_data[feature].shift(-i)\n",
    "\n",
    "        # Create the label column using future data\n",
    "\n",
    "        for i in range(1, window_size_future + 1):\n",
    "            prepared_data[cyclist_id][f'label_disrupt{i}'] = cyclist_data['disrupt'].shift(-i - window_size_past)\n",
    "            prepared_data[cyclist_id][f'label_score{i}'] = cyclist_data['score'].shift(-i - window_size_past)\n",
    "\n",
    "        prepared_data[cyclist_id]['cyclist_id'] = cyclist_id\n",
    "        # rearrange the columns to have the cyclist_id as the first column\n",
    "        prepared_data[cyclist_id] = prepared_data[cyclist_id][['cyclist_id'] + [col for col in prepared_data[cyclist_id].columns if col != 'cyclist_id']]\n",
    "\n",
    "        # drop the rows with NaN values which are the result of shifting\n",
    "        prepared_data[cyclist_id] = prepared_data[cyclist_id].dropna()\n",
    "\n",
    "        \n",
    "        # prepared_data[cyclist_id]['label'] = cyclist_data['disrupt'].shift(-window_size_past - 1).rolling(window=window_size_future).max()\n",
    "    \n",
    "    return pd.concat(prepared_data.values()).reset_index(drop=True)\n",
    "\n",
    "    # Drop the rows with NaN values which are the result of shifting\n",
    "    # prepared_data = prepared_data.dropna()\n",
    "\n",
    "    return prepared_data\n",
    "\n",
    "\n",
    "def evaluate_and_visualize_model(classifier: DecisionTreeClassifier, X_test: pd.DataFrame, y_test: pd.DataFrame):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return report\n",
    "\n",
    "\n",
    "def filter_relevant_cols_for_model(df: pd.DataFrame, label_idx=-2):\n",
    "    # Note: -2 is the \"disrupt\" column and -1 is the \"score\" column.\n",
    "    feature_cols = df.columns[:-2]  # removing the label column\n",
    "    # remove_keys = [\"date\", \"day\", \"year\", \"month\", \"workout_week\", \"workout_title\", \"workout_type\", \"tss_cal\", \"_id\"]\n",
    "    remove_keys = [\"date\", \"day\", \"year\", \"month\", \"workout_week\", \"workout_title\", \"workout_type\", \"_id\"]\n",
    "    feature_cols = list(filter(lambda col: not any([key in col for key in remove_keys]), feature_cols))\n",
    "    return feature_cols, [df.columns[label_idx]]\n",
    "\n",
    "\n",
    "def label_encoding(df: pd.DataFrame, column_names: List[str]):\n",
    "    le = LabelEncoder()\n",
    "    for column in column_names:\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_model(df: pd.DataFrame, clf):\n",
    "    feature_cols, label_cols = filter_relevant_cols_for_model(df)\n",
    "    tss_method_cols = [col for col in df.columns if \"tss_calculation_method\" in col]\n",
    "    df = label_encoding(df, tss_method_cols)\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    X = df[feature_cols]\n",
    "    y = df[label_cols]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,\n",
    "                                                        random_state=1)  # 90% training and 10% test\n",
    "\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    report = evaluate_and_visualize_model(clf, X_test, y_test)\n",
    "    return report\n",
    "\n",
    "\n",
    "def process_report(report: dict):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_windows_config_from_dir(window_dir: str, prediction_type: str) -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Get all the window configurations from the directory.\n",
    "    A file's name might be in the format of \"IllnessesTimeSeries_x3_y1.csv\" or \"InjuriesTimeSeries_x3_y7.csv\".\n",
    "\n",
    "    Args:\n",
    "        window_dir: The directory containing the window configurations.\n",
    "        prediction_type: The type of prediction, either Illnesses or Injuries.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples containing the window configurations.\n",
    "    \"\"\"\n",
    "    window_configs = []\n",
    "    for file in os.listdir(window_dir):\n",
    "        if file.startswith(f\"{prediction_type}TimeSeries\"):\n",
    "            split_file = file[:-4].split(\"_\")\n",
    "            x = int(split_file[1][1:])\n",
    "            y = int(split_file[2][1:].split(\".\")[0])\n",
    "            window_configs.append((int(x), int(y)))\n",
    "    return sorted(window_configs)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_all_configs(predict_type: str):\n",
    "        \"\"\"\n",
    "        Check all the configurations for the given prediction type.\n",
    "        \"\"\"\n",
    "        window_configs = get_all_windows_config_from_dir(\"../Data\", predict_type)\n",
    "        reports = {}\n",
    "        for x, y in window_configs:\n",
    "                time_series_df = load_data(f\"../Data/{predict_type}TimeSeries_x{x}_y{y}.csv\")\n",
    "                for clf in classifiers:\n",
    "                        print(f\"Config: x={x}, y={y}, clf={clf}\")\n",
    "                        report = create_model(time_series_df, clf=classifiers[clf])\n",
    "                        reports[(x, y, clf)] = report\n",
    "                        return reports\n",
    "        return reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = load_data(rf\"../Data/Cleaned_Agg_Workouts_2023.csv\")\n",
    "df2 = load_data(rf\"../Data/Cleaned_riderInjuries.csv\")\n",
    "df_merged = merge_selected_columns_from_dfs(df1, df2, [\"disrupt\", \"score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data = prepare_data(df_merged, 4, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
